{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1\n",
    "DAS 511, Spring 2025\n",
    "\n",
    "1. Goal: 기초 Regression 분석 파이썬 실습, 모델 비교 및 선택\n",
    "2. How: 질문이 있는 곳마다 빈칸 채우기.\n",
    "3. Submit: 블랙보드에 ipynb 파일 모두 시행 후 pdf 파일 업로드. (PDF Compile이 잘 안되는 경우 HTML Export -> 웹브라우저에서 Open -> Print -> PDF로 저장)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T10:35:14.812578Z",
     "start_time": "2025-07-31T10:35:14.810557Z"
    }
   },
   "source": [
    "# Load Packages & Moduels\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. 전체 회귀모형의 유의성 없이 개별 계수가 유의해 보일 수 있을까?\n",
    "## 과제 설명\n",
    "\n",
    "100개의 독립변수를 갖는 선형 회귀 모형을 적합해보자. 이때 종속변수 Y는 X와 아무런 상관이 없도록 무작위로 생성된다. 즉, **진짜로는 모든 계수가 0**이다.\n",
    "\n",
    "그럼에도 불구하고 우리는 통계적으로 유의해 보이는 결과를 얻을 수 있을까?\n",
    "\n",
    "아래 지침을 따라 실험하고, 결과를 분석하시오.\n",
    "\n",
    "---\n",
    "\n",
    "## 지침\n",
    "Test-Level: $\\alpha=0.05$\n",
    "1. X ~ N(0,1), shape = (500, 100) **서로 독립**\n",
    "2. Y ~ N(0,1), shape = (100, ) **X와 독립**\n",
    "3. statsmodels OLS로 선형회귀 적합\n",
    "4. 다음을 출력하시오:\n",
    "   - F-test의 p-value\n",
    "   - 각 계수의 t-test p-value들 중 0.05보다 작은 것의 개수\n",
    "5. 위 실험을 반복해서 1000번 반복해서 얼마나 자주 F-Test Reject이 일어나는지, t-test는 얼마나 False positive가 나오는지 확인\n",
    "6. 이 실험에서 얻은 결과에 대해 결론을 작성하시오.\n",
    "\n",
    "---\n",
    "\n",
    "## 목표\n",
    "\n",
    "- F-test를 통과하지 않는데도 일부 계수의 p-value가 유의해 보일 수 있음을 체험\n",
    "- 전체 모형 유의성이 먼저 검토되어야 함을 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드들의 ``pass`` 부분을 완성하시오."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T10:35:08.479008Z",
     "start_time": "2025-07-31T10:35:08.465032Z"
    }
   },
   "source": [
    "# 테스트 1\n",
    "np.random.seed(0)\n",
    "\n",
    "# 데이터 생성\n",
    "n, p = 500, 100\n",
    "X = np.random.randn(n, p)\n",
    "y = np.random.randn(n)\n",
    "\n",
    "\n",
    "# statsmodels 회귀\n",
    "pass # 여기에 답안 작성  (model 이라는 변수에 statsmodels fit 한 결과 입력)\n",
    "\n",
    "# F-test p-value\n",
    "pass # 여기에 답안 작성\n",
    "\n",
    "# 각 계수의 t-test p-values 가 0.05 보다 작은 경우 몇개가 나오는지 출력\n",
    "pvals = model.pvalues[1:]  # 상수항 제외\n",
    "significant = pvals[pvals < 0.05]\n",
    "print(f\"Number of t-tests with p < 0.05: {len(significant)}\")\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mpass\u001B[39;00m \u001B[38;5;66;03m# 여기에 답안 작성\u001B[39;00m\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# 각 계수의 t-test p-values 가 0.05 보다 작은 경우 몇개가 나오는지 출력\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m pvals = \u001B[43mmodel\u001B[49m.pvalues[\u001B[32m1\u001B[39m:]  \u001B[38;5;66;03m# 상수항 제외\u001B[39;00m\n\u001B[32m     18\u001B[39m significant = pvals[pvals < \u001B[32m0.05\u001B[39m]\n\u001B[32m     19\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mNumber of t-tests with p < 0.05: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(significant)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 2\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 설정\n",
    "n, p = 500, 100\n",
    "n_trials = 1000\n",
    "alpha = 0.05\n",
    "\n",
    "f_rejections = 0\n",
    "t_rejection_counts = []\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for _ in tqdm(range(n_trials)):\n",
    "    pass\n",
    "    # 여기에 답안 작성:\n",
    "    # 위 결과 반복, F-test reject 할 때 마다 f_rejections 하나 추가\n",
    "    # t_rejection_counts 리스트에 매 트라이얼마다 선택되는 변수의 수 추가\n",
    "\n",
    "# 결과 요약\n",
    "f_rate = f_rejections / n_trials\n",
    "t_avg = np.mean(t_rejection_counts)\n",
    "\n",
    "print(f\"\\n F-test가 유의했던 비율: {f_rate:.4f}\")\n",
    "print(f\"t-test에서 평균적으로 유의했던 계수 수: {t_avg:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(여기에 Q1 결론 작성 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "data = pd.read_csv('https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the predictor and response\n",
    "X = data.drop(columns=['Y']) \n",
    "X = pd.get_dummies(X, columns=['SEX'], drop_first=True) # drop_first=True : Dummy encoding\n",
    "y = data['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. ``train_test_split`` 함수를 사용해서 train_idx 와 test_idx 를 만드시오. \n",
    "\n",
    "**유의사항**\n",
    "- 데이터를 분리하는 게 아닌 index 셋 만들기. 활용예: ``X_train = X.iloc[train_idx]``\n",
    "- ``test_size``: 0.3\n",
    "- ``random_state``: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 Q2 답안 작성\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = X.iloc[train_idx], X.iloc[test_idx], y.iloc[train_idx], y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. ``Pipeline``을 이용해서 stanrdardize 후 Linear Regression 을 한 뒤 Train RMSE, Test RMSE report\n",
    "\n",
    "$$\n",
    "Train RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "LinReg = Pipeline(steps=[\n",
    "    ('Standardize', StandardScaler()),\n",
    "    ('LinReg', LinearRegression())\n",
    "])\n",
    "\n",
    "# 아래에 Q3 답안 작성\n",
    "pass\n",
    "\n",
    "LR_train_RMSE = None # 여기에 계산식 작성\n",
    "LR_test_RMSE = None # 여기에 계산식 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Linear'] = [LR_train_RMSE, LR_test_RMSE]\n",
    "results.index = ['Train RMSE', 'Test RMSE']\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. 5-Fold CV 를 이용해 Polynomial Regression 의 적절한 degree를 찾으시오\n",
    "\n",
    "**유의사항**\n",
    "- ``X_train``과 ``y_train`` 만을 이용해서 degree 를 찾아야 함\n",
    "- ``KFold`` 함수 활용, Set ``random_state`` to be 0.\n",
    "- ``PolynomialFeatures`` 적용 전에 Standardize 하기\n",
    "- 찾아볼 Degree는 1부터 10까지\n",
    "- ``kfold_cv`` 라는 list에 각 디그리별 CV 값 저장하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 Q4 답안 작성\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The best degree of the polynomial is {np.argmin(kfold_cv)+1}\")\n",
    "best_degree = np.argmin(kfold_cv)+1\n",
    "np.sqrt(kfold_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = best_degree\n",
    "poly_d = Pipeline(steps=[\n",
    "            ('Standardize', StandardScaler()),\n",
    "            ('poly_d-feature', PolynomialFeatures(degree=d, include_bias=False)),\n",
    "            ('LinReg', LinearRegression())\n",
    "        ])\n",
    "poly_out_d = poly_d.fit(X_train,y_train)\n",
    "\n",
    "results['Poly'] = [np.sqrt(np.mean((poly_out_d.predict(X_train)- y_train)**2)), np.sqrt(np.mean((poly_out_d.predict(X_test)- y_test)**2))]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "\n",
    "- Ridge regression 은 ``sklearn.linear_model`` 모듈의 ``Ridge`` 라는 함수를 통해 계산할 수 있다.\n",
    "- penalty parameter $\\lambda$ 는 이 함수에서는 ``alpha`` 라는 변수를 통해 조절할 수 있다.\n",
    "- Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "\n",
    "활용 예제는 다음과 같다. 다음의 경우 ``alpha=0`` 을 입력함으로서 일반 linear regression과 같은 값을 가져오게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeOut = Ridge(alpha=0).fit(X_train, y_train)\n",
    "np.sqrt(np.mean((RidgeOut.predict(X_test)-y_test)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "- 여기에서부턴 ``KFold`` 함수가 아닌 ``GridSearchCV`` 라는 함수를 통해 최적값을 찾도록 한다.\n",
    "- hyperparameter Grid를 설정 해 두면 K-fold CV 를 통해 Grid 중 최적의 Hyperparameter 설정을 해준다.\n",
    "- 필요사항: peformance measure 를 설정해주어야 한다. (MSE 등)\n",
    "- Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "**Grid for Regularization**\n",
    "- potential $\\lambda$ 에 대한 적절한 Grid로는 $10^{-7}$  혹은 $10^{-5}$ 부터 $10^2$ 혹은 $10$ 까지 값을 설정한다.\n",
    "- 유의사항으로 $\\lambda \\|\\beta\\|$ 형태의 regularization 에 대해서 Grid는 log-scale 로 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-scale v.s. linsear-scale\n",
    "print(\"log-scale: \",np.logspace(-5,2, num=10).round(5))\n",
    "print(\"linear-scale: \",np.linspace(10**(-5),10**2,num=10).round(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. log-scale 과 linear-scale grid의 차이를 간략히 설명하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(여기에 Q5 답안 작성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RidgeReg = Pipeline(steps=[\n",
    "    ('Standardize', StandardScaler()),\n",
    "    ('Ridge_reg', Ridge())\n",
    "])\n",
    "\n",
    "# Grid Search\n",
    "param_grid = {'Ridge_reg__alpha' : np.logspace(-6,2, num=15)} \n",
    "RidgeCV = GridSearchCV(RidgeReg, param_grid, cv= 7, n_jobs = 15, scoring='neg_mean_squared_error')  #scoring: CV 에 사용할 메저: MSE\n",
    "RidgeCV.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. 위 코드는 GridSearchCV 를 활용해서 Ridge regression을 하는 예제이다. ``param_grid`` 를 위와 같은 dictionary 형태로 작성한 이유를 설명하시오.\n",
    "Pipeline 으로 정의된 모델에 대한 추가 공부 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(여기에 Q6 답안 작성)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Ridge Regression의 Train RMSE, Test RMSE 를 구하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 Q7 답안 작성\n",
    "pass\n",
    "\n",
    "# Report\n",
    "Ridge_train_RMSE = None\n",
    "Ridge_test_RMSE = None\n",
    "results['Ridge'] = [Ridge_train_RMSE, Ridge_test_RMSE]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "das",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
